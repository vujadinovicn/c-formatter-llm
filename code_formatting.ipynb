{"cells":[{"cell_type":"markdown","metadata":{},"source":["Firstly, we create our SpaceDataset. We set the number of max_label_length to 50, as we have already preprocessed and prepared our dataset so every entry has less or equal than 50 tokens after parsing the AST C tree. \n","Moreover, we pad every labels sequence by adding number 100 to it. This way, every labels array will have exactly 50 elements. Later on, index/number 100 will be ignored when calculating loss and accuracy. \n","In the end, __getitem__ method returns no_of_tokens, spellings, kinds and labels for the single example."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1730145363195,"user":{"displayName":"Nemanja Vujadinovic","userId":"11888407107904542747"},"user_tz":-60},"id":"KEnsSlwINgcl"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","torch.manual_seed(0)\n","\n","class SpaceDataset(Dataset):\n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","        self.max_label_length = 50\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        no_of_tokens = len(self.dataset[idx]['token_spellings'])\n","        spellings = \" \".join(self.dataset[idx]['token_spellings'])\n","        kinds = \" \".join(self.dataset[idx]['token_kinds'])\n","        labels = self.dataset[idx]['labels']\n","\n","        if len(labels) < self.max_label_length:\n","            labels = labels + [100] * (self.max_label_length - len(labels))  # padding with 100 for as ignoring index\n","        else:\n","            labels = labels[:self.max_label_length]\n","\n","        labels = torch.tensor(labels, dtype=torch.float)\n","        return no_of_tokens, spellings, kinds, labels"]},{"cell_type":"markdown","metadata":{},"source":["We use ALBERT tranformer for obtaining relevant information on the code data. ALBERT transformer is loaded with pre-trained weights. We added one more fully connected layer on top of the transformer model for fine tuning it on our space prediction.\n","\n","Spellings and kinds are passed together as an input through the tokenizer. Later, we obtain last_hidden_state of the output and pass it through the fully connected layer. Finally, we pass previous output through the sigmoid function to obtain space prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28120,"status":"ok","timestamp":1730145363194,"user":{"displayName":"Nemanja Vujadinovic","userId":"11888407107904542747"},"user_tz":-60},"id":"m1ZaFrLZPHIt"},"outputs":[],"source":["from torch import nn\n","import torch\n","from transformers import AlbertTokenizer, AlbertModel\n","# import torch_directml\n","# dml = torch_directml.device()\n","\n","class SpaceALBERT(nn.Module):\n","    def __init__(self, pretrained_model_name='albert-base-v2'):\n","        super(SpaceALBERT, self).__init__()\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        self.model = AlbertModel.from_pretrained(pretrained_model_name).to(self.device)\n","        self.tokenizer = AlbertTokenizer.from_pretrained(pretrained_model_name)\n","        self.fc = nn.Linear(768, 1)\n","\n","    def forward(self, spellings, kinds):\n","        inputs = self.tokenizer(spellings, kinds, return_tensors='pt', padding=True, truncation=True).to(self.device)\n","        outputs = self.model(**inputs)\n","        last_hidden_state = outputs.last_hidden_state\n","        token_logits = self.fc(last_hidden_state).squeeze(-1)\n","        space_preds = torch.sigmoid(token_logits)\n","\n","        return space_preds"]},{"cell_type":"markdown","metadata":{},"source":["Here, we obtain previously processed data and create training, validation and test datasets and dataloaders."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["8ea2792a3bde49268451de78897e8f52","68adb6d56db64a1295d8e389ec0d7a68","d2a6cd26555849e68963bec6dbfa7ad3","f3fd6519e9da480dbbb20a9de6bd8e71","ccc09ccd1ba7463db2568be9ed54a479","9fb2442da97a4f99a5bea03e37ba0221","374a60fd9a2f493f817b2f785f9e9f73","687f729dd5d441e9b9a5ec08907fd2f6","9c211c6f13724b869bc8c23823928a51","f746eb4f307346819d3c5151f677131a","449992adf4a14e9896681c2c10038a0f","8e36bd37990147e6bf315e6f06b4ab5f","9e13380e2975435792bb0c55502cdb89","625e38e0251f4f3d887afac257232074","11310e617e2d4db4a944f47c2ace0e14","a2ef4fdde94340e6a9ea098f3c791bca","89f38484256e4dc6a77011d8d954a78f","256627d2524c4173a2f4cbe5d1635363","a610a329e50748c0b4bafff123a82c87","8864e1219a8e48a5b8b88f2c90fd4317","aba9a1ec23bf4fa4b530dfe1630e09ad","92c22f6ff49641049f7e8c31bafde9d3"]},"executionInfo":{"elapsed":4285,"status":"ok","timestamp":1730146469932,"user":{"displayName":"Nemanja Vujadinovic","userId":"11888407107904542747"},"user_tz":-60},"id":"BzPPlcYXTiL_","outputId":"e815f10d-a435-4ecf-8888-7526e1cdc1ce"},"outputs":[],"source":["from datasets import load_dataset\n","hf_train_set = load_dataset('json', data_files='data/train_serialized.json')['train']\n","train_set = SpaceDataset(hf_train_set)\n","train_loader = DataLoader(train_set, batch_size = 16, shuffle = True)\n","\n","hf_val_set = load_dataset('json', data_files='data/val_serialized.json')['train']\n","val_set = SpaceDataset(hf_val_set)\n","val_loader = DataLoader(val_set, batch_size = 16, shuffle = False)\n","\n","hf_test_set = load_dataset('json', data_files='data/test_serialized.json')['train']\n","test_set = SpaceDataset(hf_test_set)\n","test_loader = DataLoader(test_set, batch_size = 16, shuffle = False)"]},{"cell_type":"markdown","metadata":{},"source":["We initialize the model. For optimizer, we use Adam optimizer with learning rate of 1e-5. For computing the loss, we use BCELoss."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1246,"status":"ok","timestamp":1730146472998,"user":{"displayName":"Nemanja Vujadinovic","userId":"11888407107904542747"},"user_tz":-60},"id":"olQjmrKeoGRm"},"outputs":[],"source":["import torch.optim as optim\n","model = SpaceALBERT().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","optimizer = optim.Adam(model.parameters(), lr=1e-5)\n","criterion = nn.BCELoss()"]},{"cell_type":"markdown","metadata":{},"source":["We define our training method. For outputs, we slice it to 50, as no input sequence has more than 50 tokens in AST tree. Additionally, we apply a mask to ignore padding labels - which were set to 100 in SpaceDataset class. We calculate the loss and update the model weights."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":373,"status":"ok","timestamp":1730146475973,"user":{"displayName":"Nemanja Vujadinovic","userId":"11888407107904542747"},"user_tz":-60},"id":"BXEi37C9oCLu"},"outputs":[],"source":["def train(model, optimizer, train_loader, criterion):\n","    model.train()\n","    total_loss = 0\n","    bc = 0\n","    for batch in train_loader:\n","        optimizer.zero_grad()\n","        no_of_tokens, spellings, kinds, labels = batch\n","\n","        labels = torch.tensor(labels, dtype=torch.float).to(model.device)\n","\n","        outputs = model(spellings, kinds)\n","        outputs = outputs[:, :50]\n","\n","        mask = (labels != 100).float()\n","        masked_outputs = outputs * mask\n","        masked_labels = labels * mask\n","\n","        loss = criterion(masked_outputs, masked_labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    print(f'Training loss: {total_loss/len(train_loader)}')"]},{"cell_type":"markdown","metadata":{},"source":["Here we define our validation method. The code logic is the same as in the train method. Additionally, we obtain predictions by comparing outputs with the threshold of 0.5. After that, we apply the same mask for predictions. We calculate the loss and accuracy for validation dataset."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":343,"status":"ok","timestamp":1730146479499,"user":{"displayName":"Nemanja Vujadinovic","userId":"11888407107904542747"},"user_tz":-60},"id":"PxqSX9fIUci3"},"outputs":[],"source":["def evaluate(model, val_loader, criterion, threshold=0.5):\n","    model.eval()\n","    total_loss = 0\n","    correct_predictions = 0\n","    total_valid_predictions = 0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            no_of_tokens, spellings, kinds, labels = batch\n","\n","            labels = torch.tensor(labels, dtype=torch.float).to(model.device)\n","\n","            outputs = model(spellings, kinds)\n","            outputs = outputs[:, :50]\n","\n","            mask = (labels != 100).float()\n","            masked_outputs = outputs * mask\n","            masked_labels = labels * mask\n","\n","            loss = criterion(masked_outputs, masked_labels)\n","            total_loss += loss.item()\n","\n","            predictions = (masked_outputs > threshold).float()\n","            masked_predictions = predictions * mask\n","\n","            correct_predictions += ((masked_predictions == masked_labels) * mask).sum().item()\n","            total_valid_predictions += mask.sum().item() \n","\n","    avg_loss = total_loss / len(val_loader)\n","    accuracy = correct_predictions / total_valid_predictions * 100\n","\n","    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n","    return avg_loss, accuracy\n"]},{"cell_type":"markdown","metadata":{},"source":["Finally, we run our training process. In every epoch, we run train and evaluate methods. We obtain the accuracy and if it's higher than the latest best accuracy, we set it to new best accuracy and save the model (the output after the cell shows the results for epoch 7 and 8). "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Marko.DESKTOP-CS1PADQ\\AppData\\Local\\Temp\\ipykernel_5520\\4038505137.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels = torch.tensor(labels, dtype=torch.float).to(model.device)\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.06282496693549565\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Marko.DESKTOP-CS1PADQ\\AppData\\Local\\Temp\\ipykernel_5520\\3979003935.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels = torch.tensor(labels, dtype=torch.float).to(model.device)\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.0778, Accuracy: 89.53%\n","Training loss: 0.05721921129236799\n","Validation Loss: 0.0761, Accuracy: 90.10%\n"]}],"source":["top_accuracy = 0\n","epochs = 8\n","\n","for i in range(0, epochs):\n","  train(model, optimizer, train_loader, criterion)\n","  _, acc = evaluate(model, val_loader, criterion)\n","  if acc > top_accuracy:\n","    top_accuracy = acc\n","    model_state_dict = model.state_dict()\n","    torch.save(dict(model_state_dict=model_state_dict, epoch=i), f\"space_{i}.pkl\")"]},{"cell_type":"markdown","metadata":{},"source":["Now it's time to test our model on test dataset. Firstly, we need to load the best model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["checkpoint = torch.load(\"checkpoints/space_7.pkl\", map_location='cpu')\n","msg = model.load_state_dict(checkpoint['model_state_dict'], strict=False)"]},{"cell_type":"markdown","metadata":{},"source":["Next, we have to write evaluate_test function which is almost the same as the evaluate function."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate_test(model, threshold=0.5):\n","    model.eval()\n","    correct_predictions = 0\n","    total_valid_predictions = 0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            no_of_tokens, spellings, kinds, labels = batch\n","\n","            labels = torch.tensor(labels, dtype=torch.float).to(model.device)\n","\n","            outputs = model(spellings, kinds)\n","            outputs = outputs[:, :50]\n","\n","            mask = (labels != 100).float()\n","            masked_outputs = outputs * mask\n","            masked_labels = labels * mask\n","\n","            predictions = (masked_outputs > threshold).float()\n","            masked_predictions = predictions * mask\n","\n","            correct_predictions += ((masked_predictions == masked_labels) * mask).sum().item()\n","            total_valid_predictions += mask.sum().item() \n","\n","    accuracy = correct_predictions / total_valid_predictions * 100\n","    print(f'Test Accuracy: {accuracy:.2f}%')"]},{"cell_type":"markdown","metadata":{},"source":["Now we only have to run the previous function."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Marko.DESKTOP-CS1PADQ\\AppData\\Local\\Temp\\ipykernel_15056\\3682815981.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels = torch.tensor(labels, dtype=torch.float).to(model.device)\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 90.10%\n"]}],"source":["evaluate_test(model, test_loader, criterion)"]},{"cell_type":"markdown","metadata":{},"source":["Great! Our model achieved the accuracy of 90.1% on our test dataset after only 8 epochs."]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOD6Eh/NVGEihfZ16fHUfzF","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"11310e617e2d4db4a944f47c2ace0e14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aba9a1ec23bf4fa4b530dfe1630e09ad","placeholder":"​","style":"IPY_MODEL_92c22f6ff49641049f7e8c31bafde9d3","value":" 6412/0 [00:00&lt;00:00, 41060.98 examples/s]"}},"256627d2524c4173a2f4cbe5d1635363":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"374a60fd9a2f493f817b2f785f9e9f73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"449992adf4a14e9896681c2c10038a0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"625e38e0251f4f3d887afac257232074":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a610a329e50748c0b4bafff123a82c87","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8864e1219a8e48a5b8b88f2c90fd4317","value":1}},"687f729dd5d441e9b9a5ec08907fd2f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"68adb6d56db64a1295d8e389ec0d7a68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fb2442da97a4f99a5bea03e37ba0221","placeholder":"​","style":"IPY_MODEL_374a60fd9a2f493f817b2f785f9e9f73","value":"Generating train split: "}},"8864e1219a8e48a5b8b88f2c90fd4317":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89f38484256e4dc6a77011d8d954a78f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e36bd37990147e6bf315e6f06b4ab5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e13380e2975435792bb0c55502cdb89","IPY_MODEL_625e38e0251f4f3d887afac257232074","IPY_MODEL_11310e617e2d4db4a944f47c2ace0e14"],"layout":"IPY_MODEL_a2ef4fdde94340e6a9ea098f3c791bca"}},"8ea2792a3bde49268451de78897e8f52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68adb6d56db64a1295d8e389ec0d7a68","IPY_MODEL_d2a6cd26555849e68963bec6dbfa7ad3","IPY_MODEL_f3fd6519e9da480dbbb20a9de6bd8e71"],"layout":"IPY_MODEL_ccc09ccd1ba7463db2568be9ed54a479"}},"92c22f6ff49641049f7e8c31bafde9d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c211c6f13724b869bc8c23823928a51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e13380e2975435792bb0c55502cdb89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89f38484256e4dc6a77011d8d954a78f","placeholder":"​","style":"IPY_MODEL_256627d2524c4173a2f4cbe5d1635363","value":"Generating train split: "}},"9fb2442da97a4f99a5bea03e37ba0221":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ef4fdde94340e6a9ea098f3c791bca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a610a329e50748c0b4bafff123a82c87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"aba9a1ec23bf4fa4b530dfe1630e09ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccc09ccd1ba7463db2568be9ed54a479":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2a6cd26555849e68963bec6dbfa7ad3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_687f729dd5d441e9b9a5ec08907fd2f6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c211c6f13724b869bc8c23823928a51","value":1}},"f3fd6519e9da480dbbb20a9de6bd8e71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f746eb4f307346819d3c5151f677131a","placeholder":"​","style":"IPY_MODEL_449992adf4a14e9896681c2c10038a0f","value":" 29924/0 [00:01&lt;00:00, 25633.17 examples/s]"}},"f746eb4f307346819d3c5151f677131a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
